{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c72542a",
   "metadata": {},
   "source": [
    "# What My Goals Are\n",
    "\n",
    "## Input Data\n",
    "\n",
    "While the scraper is running, I want to find what my goals are for this project. Since I've stuck to using Earnings Calls, the similarity ratings arent all that interesting - we can find details about the companies and classify them without using NLP at all - they're literally categorized into sectors. \n",
    "\n",
    "### Analyst Opinions\n",
    "\n",
    "These are also not analyst opinions. In the future, I would absolutely want to include analyst opinions, however, for V1 of this project it doesnt make sense. To get a good overview, I'd want multiple different opinions from multiple different sources - I have a list to look at, but these are different websites, and we'd need a different scraper for each one. So thats stressful:) Additionally, sentiments would be the analysts opinion of the company rather than what the earnings said - so it would be more for processing the analysts \n",
    "\n",
    "## My Problems\n",
    "\n",
    "### The calls themselves \n",
    "I've tried listening to calls - they're so boring. Everyone tries very hard to be very polite and slippery - \"Im not saying anything and Im sure you have a good explanation and its probably a good thing, but it seems youre reporting a lost of billions of dollars, could you please clarify how thats a good thing\" \n",
    "\n",
    "Theyre exhausting to read and exhausting to listen to. Summarize, please.\n",
    "\n",
    "### Big Trends? \n",
    "There are a lot of companies. I know whats happening with the big tech ones because I've worked near them - but what about the industry? \n",
    "Can we find common topics between companies that aren't part of the company definitions - how companies are approaching offices, outsourcing, etc. \n",
    "\n",
    "## Steps \n",
    "\n",
    "### Topic Analysis \n",
    "\n",
    "### Summarizing \n",
    "Not easily covered. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c433f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup,SoupStrainer\n",
    "import re\n",
    "import os \n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.debugger import Pdb\n",
    "from random import Random, randrange\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pysentiment2 import LM \n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84732fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open text file in read mode\n",
    "text_file = open('all_documents_1000.txt', \"r\")\n",
    " \n",
    "#read whole file to a string\n",
    "raw_string = text_file.read()\n",
    " \n",
    "#close file\n",
    "text_file.close()\n",
    "raw_docs = raw_string.split('\\n********************************************************************\\n')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee092b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_file = open('all_titles_1000.txt', 'r')\n",
    "raw_titles= title_file.read()\n",
    "title_file.close()\n",
    "titles = raw_titles.split('\\n********************************************************************\\n')[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6387774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_clean(thing):\n",
    "    doc = BeautifulSoup(thing, 'html.parser')\n",
    "    a = doc.prettify()\n",
    "    a = a.replace(u'\\xa0', u' ')\n",
    "    a = a.replace(u'&amp;',u'and')\n",
    "    return a\n",
    "\n",
    "\n",
    "def split_by_sections(doc):\n",
    "    x = doc.split('<h2>\\n')\n",
    "    details_by_block = {}\n",
    "    for block in x:\n",
    "        \n",
    "        block_2 = block.split('</h2>\\n')\n",
    "        try:\n",
    "            block_text = block_2[1]\n",
    "            block_title = block_2[0]\n",
    "        except:\n",
    "            block_text = block_2[0]\n",
    "            block_title = 'header'\n",
    "        \n",
    "        details_by_block[block_title]= block_text\n",
    "    return details_by_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04e1482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big = {titles[i]:doc_clean(raw_docs[i]) for i in range(0,len(raw_docs))}\n",
    "docs = list(df_big.values())\n",
    "doc = docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4b0d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['header', '  Contents:\\n ', '  Prepared Remarks:\\n ', '  Questions and Answers:\\n ', '  Call participants:\\n '])\n",
      "dict_keys(['header', '  Contents:\\n ', '  Prepared Remarks:\\n ', '  Questions and Answers:\\n ', '  Call participants:\\n '])\n"
     ]
    }
   ],
   "source": [
    "print(split_by_sections(doc).keys())\n",
    "print(split_by_sections(docs[1]).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c58c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_split = { titles[i]: split_by_sections(docs[i]) for i in range(0, len(docs)) }\n",
    "sections_split_list = list(sections_split.values())\n",
    "df = pd.DataFrame(sections_split_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "731f0ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>header</th>\n",
       "      <th>toc</th>\n",
       "      <th>prepared_remarks</th>\n",
       "      <th>questions_and_answers</th>\n",
       "      <th>who</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;span class=\"article-content\"&gt;\\n &lt;p&gt;\\n  &lt;stron...</td>\n",
       "      <td>&lt;ul&gt;\\n  &lt;li&gt;\\n   Prepared Remarks\\n  &lt;/li&gt;\\n ...</td>\n",
       "      <td>&lt;p&gt;\\n  &lt;strong&gt;\\n   Operator\\n  &lt;/strong&gt;\\n &lt;...</td>\n",
       "      <td>&lt;p&gt;\\n  &lt;strong&gt;\\n   Operator\\n  &lt;/strong&gt;\\n &lt;...</td>\n",
       "      <td>&lt;p&gt;\\n  &lt;strong&gt;\\n   Douglas C. Yearley\\n  &lt;/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;span class=\"article-content\"&gt;\\n &lt;p&gt;\\n  &lt;stron...</td>\n",
       "      <td>&lt;ul&gt;\\n  &lt;li&gt;\\n   Prepared Remarks\\n  &lt;/li&gt;\\n ...</td>\n",
       "      <td>&lt;br data-uw-rm-sr=\"\" role=\"presentation\"/&gt;\\n ...</td>\n",
       "      <td>&lt;br data-uw-rm-sr=\"\" role=\"presentation\"/&gt;\\n ...</td>\n",
       "      <td>&lt;p&gt;\\n  &lt;strong&gt;\\n   Megan Britt\\n  &lt;/strong&gt;\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;span class=\"article-content\"&gt;\\n &lt;p&gt;\\n  &lt;stron...</td>\n",
       "      <td>&lt;ul&gt;\\n  &lt;li&gt;\\n   Prepared Remarks\\n  &lt;/li&gt;\\n ...</td>\n",
       "      <td>&lt;br/&gt;\\n &lt;p&gt;\\n  &lt;strong&gt;\\n   Operator\\n  &lt;/str...</td>\n",
       "      <td>&lt;br/&gt;\\n &lt;p&gt;\\n  &lt;strong&gt;\\n   Operator\\n  &lt;/str...</td>\n",
       "      <td>&lt;p&gt;\\n  &lt;strong&gt;\\n   Whitney Notaro\\n  &lt;/stron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;span class=\"article-content\"&gt;\\n &lt;p&gt;\\n  &lt;stron...</td>\n",
       "      <td>&lt;ul&gt;\\n  &lt;li&gt;\\n   Prepared Remarks\\n  &lt;/li&gt;\\n ...</td>\n",
       "      <td>&lt;br data-uw-rm-sr=\"\" role=\"presentation\"/&gt;\\n ...</td>\n",
       "      <td>&lt;br data-uw-rm-sr=\"\" role=\"presentation\"/&gt;\\n ...</td>\n",
       "      <td>&lt;p&gt;\\n  &lt;strong&gt;\\n   Vince Klinges\\n  &lt;/strong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;span class=\"article-content\"&gt;\\n &lt;p&gt;\\n  &lt;stron...</td>\n",
       "      <td>&lt;ul&gt;\\n  &lt;li&gt;\\n   Prepared Remarks\\n  &lt;/li&gt;\\n ...</td>\n",
       "      <td>&lt;br data-uw-rm-sr=\"\" role=\"presentation\"/&gt;\\n ...</td>\n",
       "      <td>&lt;br data-uw-rm-sr=\"\" role=\"presentation\"/&gt;\\n ...</td>\n",
       "      <td>&lt;p&gt;\\n  &lt;strong&gt;\\n   David Atchley\\n  &lt;/strong...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              header  \\\n",
       "0  <span class=\"article-content\">\\n <p>\\n  <stron...   \n",
       "1  <span class=\"article-content\">\\n <p>\\n  <stron...   \n",
       "2  <span class=\"article-content\">\\n <p>\\n  <stron...   \n",
       "3  <span class=\"article-content\">\\n <p>\\n  <stron...   \n",
       "4  <span class=\"article-content\">\\n <p>\\n  <stron...   \n",
       "\n",
       "                                                 toc  \\\n",
       "0   <ul>\\n  <li>\\n   Prepared Remarks\\n  </li>\\n ...   \n",
       "1   <ul>\\n  <li>\\n   Prepared Remarks\\n  </li>\\n ...   \n",
       "2   <ul>\\n  <li>\\n   Prepared Remarks\\n  </li>\\n ...   \n",
       "3   <ul>\\n  <li>\\n   Prepared Remarks\\n  </li>\\n ...   \n",
       "4   <ul>\\n  <li>\\n   Prepared Remarks\\n  </li>\\n ...   \n",
       "\n",
       "                                    prepared_remarks  \\\n",
       "0   <p>\\n  <strong>\\n   Operator\\n  </strong>\\n <...   \n",
       "1   <br data-uw-rm-sr=\"\" role=\"presentation\"/>\\n ...   \n",
       "2   <br/>\\n <p>\\n  <strong>\\n   Operator\\n  </str...   \n",
       "3   <br data-uw-rm-sr=\"\" role=\"presentation\"/>\\n ...   \n",
       "4   <br data-uw-rm-sr=\"\" role=\"presentation\"/>\\n ...   \n",
       "\n",
       "                               questions_and_answers  \\\n",
       "0   <p>\\n  <strong>\\n   Operator\\n  </strong>\\n <...   \n",
       "1   <br data-uw-rm-sr=\"\" role=\"presentation\"/>\\n ...   \n",
       "2   <br/>\\n <p>\\n  <strong>\\n   Operator\\n  </str...   \n",
       "3   <br data-uw-rm-sr=\"\" role=\"presentation\"/>\\n ...   \n",
       "4   <br data-uw-rm-sr=\"\" role=\"presentation\"/>\\n ...   \n",
       "\n",
       "                                                 who  \n",
       "0   <p>\\n  <strong>\\n   Douglas C. Yearley\\n  </s...  \n",
       "1   <p>\\n  <strong>\\n   Megan Britt\\n  </strong>\\...  \n",
       "2   <p>\\n  <strong>\\n   Whitney Notaro\\n  </stron...  \n",
       "3   <p>\\n  <strong>\\n   Vince Klinges\\n  </strong...  \n",
       "4   <p>\\n  <strong>\\n   David Atchley\\n  </strong...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['header','toc','prepared_remarks','questions_and_answers','who']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18ecc1c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def clean_prepared(pp):\n",
    "    p = BeautifulSoup(pp, 'html.parser').text\n",
    "    p = p.replace(u'\\n\\n', u' ')\n",
    "    p = p.replace(u'\\n', u'')\n",
    "    try:\n",
    "        p = p.split('    --     ', 1)[1]\n",
    "    except:\n",
    "        p=p\n",
    "    try:\n",
    "        p = p.split('     ', 1)[1]\n",
    "    except:\n",
    "        p=p\n",
    "        \n",
    "    return p\n",
    "\n",
    "#Lets start with the prepared remarks\n",
    "p = [clean_prepared(p) for p in list(df['prepared_remarks'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2897e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pos_tag(word_tokenize(p[0]))\n",
    "entities = ne_chunk(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d30a38eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.018, 'neu': 0.845, 'pos': 0.138, 'compound': 0.9999}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "score = analyzer.polarity_scores(p[500])\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
